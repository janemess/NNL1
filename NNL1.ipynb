{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используемые директории\n",
    "directory = \"C:/Users/hev20/OneDrive/Рабочий стол/Мага 1сем/flowers/\"\n",
    "directory_test = \"C:/Users/hev20/OneDrive/Рабочий стол/Мага 1сем/flowers_test/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренировочные данные\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "             directory,\n",
    "             subset='training',\n",
    "             validation_split=0.2,\n",
    "             image_size=IMAGE_SIZE,\n",
    "             batch_size=BATCH_SIZE,\n",
    "             seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валидационные данные\n",
    "valid_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            directory,\n",
    "            subset='validation',\n",
    "            validation_split=0.2,\n",
    "            image_size=IMAGE_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "             seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.class_names\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = LabelEncoder()\n",
    "class_names_label_encode = label_encode.fit_transform(class_names)\n",
    "class_names_label_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label, image_shape=224):\n",
    "    \n",
    "    img = tf.image.resize(image, [image_shape, image_shape])\n",
    "    img = img/225.\n",
    "    \n",
    "    return tf.cast(img, tf.float32), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the preprocess_image to train_data\n",
    "train_data = train_data.map(map_func=preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# shuffle the data\n",
    "train_data = train_data.shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# map the preprocess_image to valid_data\n",
    "valid_data = valid_data.map(map_func=preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# shuffle the data\n",
    "valid_data = valid_data.shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3\n",
    "model_5 = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=4, padding='same', activation='relu',input_shape=(224,224,3)),\n",
    "    MaxPool2D(2,2),\n",
    "    Conv2D(filters=64, kernel_size=4, padding='same', activation='relu'),\n",
    "    MaxPool2D(2,2), \n",
    "    Conv2D(filters=128, kernel_size=4, padding='same', activation='relu'),\n",
    "    MaxPool2D(2,2),\n",
    "    Conv2D(filters=128, kernel_size=4, padding='same', activation='relu'),\n",
    "    MaxPool2D(2,2),\n",
    "    # Dropout(0.5),\n",
    "    Flatten(),\n",
    "    # Dense(512, activation='relu'),\n",
    "    Dense(len(class_names_label_encode), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_5.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# Fit\n",
    "history_1 = model_5.fit(train_data,\n",
    "                       epochs=10,\n",
    "                       validation_data=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "    plt.plot(epochs, loss, label='training_loss')\n",
    "    plt.plot(epochs, val_loss, label='val_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "  # Plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "plot_loss_curves(history=history_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, tit = preprocess_image(image=img, label='rose')\n",
    "print(im.shape)\n",
    "im = im[np.newaxis, :, :, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model_5, \n",
    "                                         tf.keras.layers.Softmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(im)\n",
    "print(model_5.predict(im))\n",
    "\n",
    "class_names[np.argmax(predictions[0])]\n",
    "\n",
    "img = plt.imread(directory_test + \"dandelion2.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.title(\"prediction: \" + str(class_names[np.argmax(predictions[0])]))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Inception V3 model\n",
    "base_model_inception = tf.keras.applications.inception_v3.InceptionV3(include_top=False)\n",
    "\n",
    "# Freeze the layers\n",
    "base_model_inception.trainable=False\n",
    "\n",
    "# Inputs\n",
    "inputs = tf.keras.layers.Input(shape=(224,224,3), name='input_layer')\n",
    "\n",
    "# Scaling the values\n",
    "x = tf.keras.layers.experimental.preprocessing.Rescaling(1/255.)(inputs)\n",
    "\n",
    "# Pass inputs to our base_model\n",
    "x = base_model_inception(inputs,training=False)\n",
    "\n",
    "# GlobalAveragePooling2D\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# outputs\n",
    "outputs = tf.keras.layers.Dense(len(class_names_label_encode), activation='softmax')(x)\n",
    "\n",
    "# Build model\n",
    "model_v3 = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_v3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history_v3 = model_v3.fit(train_data,\n",
    "                       epochs=10,\n",
    "                       validation_data=valid_data)\n",
    "\n",
    "plot_loss_curves(history_v3)\n",
    "\n",
    "im, tit = preprocess_image(image=img, label='rose')\n",
    "print(im.shape)\n",
    "im = im[np.newaxis, :, :, :]\n",
    "\n",
    "probability_model = tf.keras.Sequential([model_v3, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(im)\n",
    "print(model_v3.predict(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names[np.argmax(predictions[0])]\n",
    "\n",
    "img = plt.imread(directory_test + \"sunflower1.jpg\")\n",
    "plt.imshow(img)\n",
    "plt.title(\"prediction: \" + str(class_names[np.argmax(predictions[0])]))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68856e79dd3f3d24f4bf75a185b5d92ccad2dc3e5145c1dbe1caab3a8c66ff8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
